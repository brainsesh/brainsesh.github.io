<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning to Think - Decoding Dualformer</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            color: #333;
        }
        h1, h2 {
            color: #0056b3;
        }
        .interactive-image {
            text-align: center;
            margin: 20px 0;
        }
        .interactive-image img {
            width: 450px; 
            height: auto; 
            cursor: pointer;
            transition: transform 0.3s ease;
            display: block; 
            margin: 0 auto; 
        }
        .interactive-image img:hover {
            transform: scale(2.5);
        }
        .non-interactive-image {
            text-align: center;
            margin: 20px 0;
        }
        .non-interactive-image img {
            width: 450px; /* Fixed width */
            height: auto; /* Maintain aspect ratio */
            display: block; /* Ensures the image is centered */
            margin: 0 auto; /* Centers the image horizontally */
        }
        .highlight {
            background-color: #f0f8ff;
            padding: 5px;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <h1>Learning to Think - Decoding Dualformer</h1>
    <p><em>(bridging system 1 and system 2 thinking through transformers)</em></p>
    <p style="font-size: 0.9em; line-height: 1.3;">
        <em><b>Author:</b> <a href="https://www.linkedin.com/in/lavanya-basavaraju/" target="_blank">Lavanya Basavaraju</a>; Published on July 04, 2025 </em><br>
        <em>If you have any questions and/or feedback, feel free to reach out at <a href="mailto:brainsesh@gmail.com">brainsesh@gmail.com</a></em>
    </p>

    <p>In this article, I talk about my understanding, key takeaways and personal impressions on the <em><a href="https://arxiv.org/pdf/2410.09918v1" target="_blank">“Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces”</a></em> paper released by FAIR at Meta on October 15, 2024.</p>

    <h3>Why is this paper interesting? </h3>
    <p>A lot of focus today in the space of Artificial Intelligence (AI) is about a single model that can think and reason at par with an average human being or better than an average human being. There is substantial curiosity and active research around how the large language models can think, reason, and act with the help of agentic frameworks. We will not get into that here. We will talk about <em><b>thinking</b></em>. The process of thinking, the psychology of thinking, and the reproducibility of thinking. The last one is where this paper comes in. So, let’s start! </p>

    <h3>1. The process and the psychology of thinking    </h2>

    <p>Well, a great deal of civilization is a product of thinking. But if we were to understand the process of thinking, dual process theory is one of the key concepts. First explained by Wason and Evans in 1974 and popularized by Kahneman in 2017 (Thinking Fast and Slow), dual process theory proposes that human cognition operates through two distinct systems of thinking.</p>
    <ul>
        <li><strong>System 1:</strong> fast, automatic and intuitive </li>
        <li><strong>System 2:</strong> slow, deliberate and effortful </li>
    </ul>

    <div class="non-interactive-image">
        <img src="system.jpg" alt="systems" title="systems of thinking">
        <p><em>System 1 vs System 2 Thinking</em></p>
    </div>


    <p>
    Essentially, System 1 relies on mental shortcuts easily at disposal from memory to make quick opinions, judgements and decisions, and System 2 requires cognitive resources for systematic reasoning, analysis and typically comes into play when called to make more careful evaluation.
    <br> <br>
    And there is a beautiful play of information, speed and accuracy that becomes essential to look at as we understand this dual process theory for thinking. One always has some information to make a decision, even it is from memory or some kind of input at the moment. System 1 will use that information to make the decision fast, while System 2 might just wait a little longer to collect more information if necessary.
    <br> <br>
    Some decisions, for example, <em>what one would like to eat for breakfast</em>, might not require to be so accurate as the risk of making that decision could be low in most situations excluding people with serious health concerns. In that case System 1 thinking is all that’s need. But say decisions like <em>where would one go to school for a graduate degree</em> or <em>is it the right time to buy a home for a young family</em>, where the risk involved is much higher would require more thought, information and analysis. <b>Sometimes this does not just need one person’s System 2 thinking but multiple trusted individuals and their System 2 thinking to make decisions</b>.
    </p>
   
    <h3>2. Ideas explored in the paper  </h2>

    <p>Dualformer is a novel transformer-based architecture that integrates both fast and slow reasoning modes into a single model, inspired by this dual process theory. The model addresses a fundamental trade-off in AI reasoning systems: fast models are computationally efficient but less accurate, while slow models that generate detailed reasoning traces are more accurate but computationally expensive.</p>

    <p>The core innovation lies in structured trace dropping during training. Instead of training separate models for fast and slow reasoning, Dualformer learns from randomized reasoning traces where different parts are systematically dropped according to four hierarchical levels:<p>
    <ul>
        <li><strong>Level 1:</strong> Drop "close" clauses from <em><a href="https://arxiv.org/pdf/2402.14083" target="_blank">A* search</a></em> traces</li>
        <li><strong>Level 2:</strong> Additionally drop cost information from remaining clauses</li>
        <li><strong>Level 3:</strong> Further drop 30% of "create" clauses randomly</li>
        <li><strong>Level 4:</strong> Drop the entire reasoning trace, keeping only the final solution</li>
    </ul>

    <p>Imagine training a new detective (say, an intern) by showing them case files with varying levels of detail.</p>
    <ul>
        <li><strong>Level 0:</strong> Here the intern detective has all information at once for full methodical investigation </li>
        <li><strong>Level 1:</strong> Here “close” clauses are hidden, meaning the detective does not know the investigations that are "closed" and the final outcome, still has all active leads and costs of pursuing these leads, etc. </li>
        <li><strong>Level 2:</strong> Here both “close” clauses and cost calculations are removed, meaning the detective does not know the closed investigations, final outcome and the cost of pursuing those investigations </li>
        <li><strong>Level 3:</strong> Here random 30% of “create” clauses are dropped, meaning the detective does not have information about 30% of the investigation cases </li>
        <li><strong>Level 4:</strong> Drop entire reasoning trace, meaning the detective is given the final outcome of the entire case without any notes on investigation and the intern detective has to trace back all the investigation </li>
    </ul>
    
    <p>The idea is that this systematic variation teaches the intern detective to solve cases efficiently when they are really working on an active case. Beautiful!</p>

    <div class="non-interactive-image">
        <img src="model.jpg" alt="model" title="model architecture" style="width: 800px; height: auto;">
    </div>
    
    <p>More about A* algorithm can be understood from <em><a href="https://arxiv.org/pdf/2402.14083" target="_blank">Searchformer </a></em> paper released by Meta in April 2024. Very briefly, A* is a pathfinding algorithm that finds the shortest route between two points, like navigating through a maze from start to goal. </p>

    <ul>
    <li> It works by maintaining two lists: a "create" list of locations it might explore next, and a "close" list of locations it has already checked.   </li>
        <ul>
            <li> For each potential location, A* calculates two key values: the actual cost to reach that spot from the start, and a heuristic estimate of how far it still is from the goal (like manhattan distance in a grid). It combines these to prioritize which location to explore next, always choosing the most promising option.   </li>
        </ul>
    <li> From the intern detective perspective, say there are 2 files – “active leads” (create list) of potential clues to investigate next and “case closed” (close list) of leads already thoroughly examined.    </li>
        <ul>   
            <li> For each active lead, the intern detective should calculate both the effort already invested to reach that point and estimate the remaining work needed to solve the case, always pursuing the most promising lead first.   </li>
        </ul> 
    </ul>
    <p>During training, each example randomly selects a dropping strategy from these levels, enabling the model to learn shortcuts in reasoning while maintaining the ability to generate full traces when needed. At inference time, Dualformer can operate in three modes:</p>
    <ul>
        <li><strong>Fast mode:</strong> Outputs solutions directly without reasoning steps</li>
        <li><strong>Slow mode:</strong> Generates complete reasoning traces plus solutions</li>
        <li><strong>Auto mode:</strong> Automatically decides which approach to use</li>
    </ul>

    <div class="non-interactive-image">
        <img src="mode.jpg" alt="modes" title="inference modes" style="width: auto; height: 200px;">
        <p><em>Inference Modes of Dualformer</em></p>
    </div>


    <p>So, Dualformer is suggesting a unified system that can dynamically adjust its reasoning depth based on task requirements and user preferences. This mimics the human thinking process, where we unconsciously switch between intuitive quick decisions (System 1) and deliberate analytical thinking (System 2) depending on the situation's complexity and stakes.</p>
    <p>The approach also addresses practical deployment concerns: a single model that can operate in multiple modes is more efficient than maintaining separate systems, while the structured dropping reduces training time by shortening input sequences.</p>


    <h3>3. Model Architecture </h3>

    <div class="non-interactive-image">
        <img src="architecture.jpg" alt="architecture" title="architecture" style="width: auto; height: 500px;">
        <p><em>Encoder-Decoder Architecture</em></p>
    </div>

    <p>Most of the large generative models today use decoder-only framework. Dualformer uses the encoder-decoder architecture, originally as explained in Attention is all you need <a href="https://arxiv.org/pdf/1706.03762" target="_blank">(Vaswani et al., 2017)</a> and T5 architecture <a href="https://arxiv.org/pdf/1910.10683" target="_blank">(Raffel et al., 2020)</a>. A few changes include the rotary position encoding (RoPE) and the format of sequences. The <b>&lt;prompt&gt;</b> goes into the encoder along with the task specification. Decoder processes either a <b>&lt;trace&gt;</b><b>&lt;plan&gt;</b> sequence (slow mode or search-augmented model) or only a <b>&lt;plan&gt;</b> sequence (fast mode or solution-only models).</p>

    <p>The models are instantiated with T5 and RoPE for position encoding, and trained with 100K training samples. Model sizes are 15M and 46M for Maze and Sokoban tasks respectively. </p>

    <p>For the fast mode, Dualformer is trained on sequence data that only include the optimal final solution, without any reasoning trace. The slow mode baseline is the Complete-Trace model trained on data with complete A* search traces.</p>

    <h3>4. Experiments and Evidence </h3>

    <p>I really liked the experimental design. The authors are basically trying to answer 3 key questions which align with not only the thinking process but also how one would want to use a large language model today for reasoning. Here are the 3 questions around which the experiments are conducted,</p>
    <ul>
        <li>Does Dualformer outperform corresponding baselines in fast, slow and auto mode? Does it generate more diverse plans? </li>
        <li>In slow model, does Dualformer lead to faster reasoning, i.e., output a shorter trace?</li>
        <li>Does the structured trace dropping technique generalize to LLMs trained on natural language datasets?</li>
    </ul>

    <p>In terms of evaluation process, whether a model generates correct and optimal plans is measured using two metrics: <b>1-Solved-64</b> and <b>1-Optimal-64</b>. </p>
    <ul>
        <li>64 responses are randomly sampled from a trained model </li>
        <li>Each response is parsed and evaluated regardless of the generated trace part</li>
        <li>If any of the 64 plans is correct, i.e. is feasible and reaches the goal location, this task is labelled as success for the 1-Solved-64 metric</li>
        <li>If any of the 64 plans is optimal, this task is labelled as success for the 1-Optimal-64 metric </li>
        <li>This is repeated for 1000 unseen evaluation tasks and report the average success rate</li>
        <li>To investigate the robustness of each method, metrics 3-Solved-64 and 3-Optimal-64, where a task is labelled as success if at least 3 plans are correct or optimal are also reported</li>
    </ul>
    <p>The authors conducted experiments across pathfinding tasks and mathematical reasoning to validate Dualformer's effectiveness. </p>

    <p>For pathfinding, they used maze navigation (15×15 to 30×30) and Sokoban puzzles with 100k training examples from A* search traces. Results demonstrated substantial improvements: </p>
    <ul>    
    <li>Fast Mode achieved 80% optimal solutions on 30×30 mazes versus 30% for solution-only baselines (2.67× improvement), </li>
    <li>Slow Mode reached 97.6% optimal rate using 45.5% fewer reasoning steps than complete-trace baselines, and</li>
    <li>Auto Mode delivered 96.6% optimal performance with 59.9% fewer steps than Searchformer and generated significantly more diverse valid solutions (18.23 vs 1.86 unique paths per task).</li>
    </ul>

    <p>
    To answer the third question, “does the structured trace dropping technique generalize to LLMs trained on natural language datasets?”, the authors conducted mathematical reasoning experiments by fine-tuning Llama-3.1-8B and Mistral-7B models on the Aug-MATH dataset. 
    <br> <br>
    This Aug-MATH dataset creation is a nice piece of experiment in itself. The dataset is derived from the MATH dataset (Hendrycks et al., 2021) that contains 7500 training examples of math questions and solutions, and 5000 testing examples. They take this data and use Llama-3.1-70B-Instruct model to rewrite the solutions with detailed intermediate steps. And then to introduce diversity, they sample 4 responses for each question. This produces an overall dataset of 30K training examples and 5K testing examples. 
    <br>  <br>   
    The evaluation shows consistent improvements from LLM finetuning, which proves that using this framework can be generalized. The key ideas is, if one were to finetune this framework for a specific reasoning task, one can achieve much better performance compared to baseline.
    </p>
    
    <!-- <div class="non-interactive-image">
        <img src="maze.jpg" alt="maze" title="experiments" style="width: 600px; height: auto;">
        <p><em>Inference Modes of Dualformer</em></p>
    </div> -->

    <h3>5. Final Thoughts</h3>
    
    <p>Overall, Dualformer presents a compelling framework that bridges the gap between fast intuitive responses and deliberate reasoning by training models that can adapt to different thinking modes. </p>
    
    <p>What makes this work particularly thought-provoking is its technical reproducibility of human-like cognitive processes, the ability to seamlessly switch between System 1 and System 2 thinking patterns, while simultaneously reducing computational overhead through intelligent sequence shortening and learning from randomized reasoning traces.</p>
    
    <p>The authors' choice to explore encoder-decoder architectures alongside the dominant decoder-only paradigm demonstrates refreshing architectural diversity and suggests potential avenues for sophisticated reasoning capabilities that extend beyond current approaches. It will be fascinating to see if this line of research and experimentation can make small reasoning models perform better and more generalizable. </p>
    
    <p>In short, my key takeaways from the paper are:</p>
    <ul>
        <li>Process of thinking and technical reproducibility of that </li>
        <li>Training a model to learn to think in fast and slow mode using randomized reasoning traces (elegance!)  </li>
        <li>While encoding-only architectures excel and large decoder-only models continue to impress, the encoder-decoder approach explored in Dualformer emerges as potentially crucial for sophisticated thinking and reasoning capabilities (big fan!) </li>
    </ul>
    <p>Kudos to all the authors and stakeholders who took this idea and produced quality studies with meaningful results (not all ideas are pursued, not all pursued ideas are successful, it is a hard process!)</p>
    <br>

    <p><b>Thanks for reading!</b></p>
    <!-- <br> -->
    <p style="font-size: 0.9em; line-height: 1.2;">
        <em>For more information, read the paper <a href="https://arxiv.org/pdf/2410.09918v1" target="_blank">here</a>. For more articles like this, visit <a href="https://brainsesh.github.io/" target="_blank">blog</a>.</em><br>
        <em>If you have any questions and/or feedback, feel free to reach out at <a href="mailto:brainsesh@gmail.com">brainsesh@gmail.com</a></em><br>
        <em>This article is licensed under <a href="https://creativecommons.org/licenses/by/4.0/legalcode" target="_blank">CC BY 4.0</a></em> <br>
        <!-- <em>Research Partners: Ryan Borowicz, Claude Sonnet 4, illuminate.google.com</em><br> -->
    </p>


</body>
</html>