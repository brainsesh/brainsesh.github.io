<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning to Think - Decoding Dualformer</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            color: #333;
        }
        h1, h2 {
            color: #0056b3;
        }
        .interactive-image {
            text-align: center;
            margin: 20px 0;
        }
        .interactive-image img {
            width: 450px; 
            height: auto; 
            cursor: pointer;
            transition: transform 0.3s ease;
            display: block; 
            margin: 0 auto; 
        }
        .interactive-image img:hover {
            transform: scale(2.5);
        }
        .non-interactive-image {
            text-align: center;
            margin: 20px 0;
        }
        .non-interactive-image img {
            width: 450px; /* Fixed width */
            height: auto; /* Maintain aspect ratio */
            display: block; /* Ensures the image is centered */
            margin: 0 auto; /* Centers the image horizontally */
        }
        .highlight {
            background-color: #f0f8ff;
            padding: 5px;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <h1>Learning to Think - Decoding Dualformer</h1>
    <p><em>(bridging system 1 and system 2 thinking through transformers)</em></p>

    <p>In this article, I talk about my understanding, key takeaways and personal impressions on the <a href="https://arxiv.org/pdf/2410.09918v1" target="_blank">“Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces”</a> paper released by meta in oct 2024.</p>

    <h3>Why is this paper interesting? </h3>
    <p>A lot of focus today in the space of Artificial Intelligence (AI) is about a single model that can think and reason at par with an average human being or better than an average human being. There is substantial curiosity and active research today around how the large language models can think, reason, and act with the help of agentic frameworks. We will not get into that here. We will talk about <em><b>thinking</b></em>. The process of thinking, the philosophy of thinking, and the reproducibility of thinking. The last one is where this paper comes in!  </p>

    <p>So, let’s start. </p>

    <h3>1. The process and the philosophy of thinking    </h2>

    <p>Well, a great deal of civilization is a product of thinking. But if we were to understand the process of thinking, dual process theory is one of the key concepts. First explained by Wason and Evans in 1974 and popularized by Kahneman in 2017 (Thinking Fast and Slow), dual process theory proposes that human cognition operates through two distinct systems of thinking.</p>
    <ul>
        <li><strong>System 1:</strong> fast, automatic and intuitive </li>
        <li><strong>System 2:</strong> slow, deliberate and effortful </li>
    </ul>

    <div class="non-interactive-image">
        <img src="system.jpg" alt="systems" title="systems of thinking">
        <p><em>System 1 vs System 2 Thinking</em></p>
    </div>

    <p>Essentially, System 1 relies on mental shortcuts easily at disposal from memory to make quick opinions, judgements and decisions, and System 2 requires cognitive resources for systematic reasoning and analysis and typically comes into play when called to make more careful evaluation. </p>

    <p>And there is a beautiful play of information, speed and accuracy that becomes essential to look at as we understand this dual process theory for thinking. You always have some information to make a decision, even it is from memory or some kind of input at the moment. System 1 will use that information to make the decision fast, which System 2 might just wait a little longer to collect more information if necessary. </p>

    <p>Some decisions, like what you would like to eat for breakfast, might not require you to be so accurate as the risk of making that decision could be low in most situations excluding people with serious health concerns. In that case System 1 thinking is all we need. But say decisions like where would one go to school for a graduate degree or is it the right time to buy a home for a young family, where the risk involved is much higher would require more thought, information and analysis. Sometime this does not just need one person’s System 2 thinking but multiple trusted individuals and their System 2 thinking to make decisions.</p>

    <h3>2. Ideas explored in the paper  </h2>

    <p>Dualformer is a novel transformer-based architecture that integrates both fast and slow reasoning modes into a single model, inspired by this dual process theory. The model addresses a fundamental trade-off in AI reasoning systems: fast models are computationally efficient but less accurate, while slow models that generate detailed reasoning traces are more accurate but computationally expensive.</p>

    <p>The core innovation lies in structured trace dropping during training. Instead of training separate models for fast and slow reasoning, Dualformer learns from randomized reasoning traces where different parts are systematically dropped according to four hierarchical levels:<p>
    <ul>
        <li><strong>Level 1:</strong> Drop "close" clauses from A* search (paper reference) traces</li>
        <li><strong>Level 2:</strong> Additionally drop cost information from remaining clauses</li>
        <li><strong>Level 3:</strong> Further drop 30% of "create" clauses randomly</li>
        <li><strong>Level 4:</strong> Drop the entire reasoning trace, keeping only the final solution</li>
    </ul>

    <div class="non-interactive-image">
        <img src="model.jpg" alt="model" title="model architecture" style="width: 800px; height: auto;">
    </div>

    <p>At this point, It is okay to not fully understand A* algorithm. We will get to that in another blog. But briefly, A* is a pathfinding algorithm that finds the shortest route between two points, like navigating through a maze from start to goal. It works by maintaining two lists: a "create" list of  locations it might explore next, and a "close" list of locations it has already checked. For each potential location, A* calculates two key values: the actual cost to reach that spot from the start, and a heuristic estimate of how far it still is from the goal (like Manhattan distance in a grid). It combines these to prioritize which location to explore next, always choosing the most promising option.</p>

    <p>During training, each example randomly selects a dropping strategy from these levels, enabling the model to learn shortcuts in reasoning while maintaining the ability to generate full traces when needed. At inference time, Dualformer can operate in three modes:</p>
    <ul>
        <li><strong>Fast mode:</strong> Outputs solutions directly without reasoning steps</li>
        <li><strong>Slow mode:</strong> Generates complete reasoning traces plus solutions</li>
        <li><strong>Auto mode:</strong> Automatically decides which approach to use</li>
    </ul>

    <div class="non-interactive-image">
        <img src="mode.jpg" alt="modes" title="inference modes" style="width: auto; height: 200px;">
        <p><em>Inference Modes of Dualformer</em></p>
    </div>


    <p>So, Dualformer is suggesting a unified system that can dynamically adjust its reasoning depth based on task requirements and user preferences. This mimics the human thinking process, where we unconsciously switch between intuitive quick decisions (System 1) and deliberate analytical thinking (System 2) depending on the situation's complexity and stakes.</p>
    <p>The approach also addresses practical deployment concerns: a single model that can operate in multiple modes is more efficient than maintaining separate systems, while the structured dropping reduces training time by shortening input sequences.</p>


    <h3>3. Model Architecture </h3>

    <div class="non-interactive-image">
        <img src="architecture.jpg" alt="architecture" title="architecture" style="width: auto; height: 500px;">
        <p><em>Encoder-Decoder Architecture</em></p>
    </div>

    <p>Dualformer use the encoder-decoder architecture, originally as explained in Attention is all you need <a href="https://arxiv.org/pdf/1706.03762" target="_blank">(Vaswani et al., 2017)</a> and T5 architecture <a href="https://arxiv.org/pdf/1910.10683" target="_blank">(Raffel et al., 2020)</a>. A few changes include the rotary position encoding (RoPE) and the format of sequences. The <b>&lt;prompt&gt;</b> goes into the encoder along with the task specification. Decoder processes either a <b>&lt;trace&gt;</b><b>&lt;plan&gt;</b> sequence (slow mode or search-augmented model) or only a <b>&lt;plan&gt;</b> sequence (fast mode or solution-only models).</p>

    <p>The models are trained with 100K training samples. Model size being 15M and 46M for Maze and Sokoban tasks respectively. </p>

    <p>For the fast mode, Dualformer is trained on sequence data that only include the optimal final solution, without any reasoning trace. The slow mode baseline is the Complete-Trace model trained on data with complete A* search traces.</p>

    <h3>4. Experiments and Evidence </h3>

    <p>Whether a model generates correct and optimal plans is measured using two metrics: <b>1-Solved-64</b> and <b>1-Optimal-64</b>. So 64 responses are randomly sampled from a trained model. Each response is parsed and evaluated regardless of the generated trace part. If any of the 64 plans is correct, i.e. is feasible and reaches the goal location, this task is labelled as success for the 1-Solved-64 metric. If any of the 64 plans is optimal, this task is labelled as success for the 1-Optimal-64 metric. This is repeated for 1000 unseen evaluation tasks and report the average success rate. To investigate the robustness of each method, metrics 3-Solved-64 and 3-Optimal-64, where a task is labelled as success if at least 3 plans are correct or optimal are also reported.</p>
    
    <p>The authors conducted comprehensive experiments across pathfinding tasks and mathematical reasoning to validate Dualformer's effectiveness. For pathfinding, they used maze navigation (15×15 to 30×30) and Sokoban puzzles with 100k training examples from A* search traces. Results demonstrated substantial improvements: Fast Mode achieved 80% optimal solutions on 30×30 mazes versus 30% for solution-only baselines (2.67× improvement), while Slow Mode reached 97.6% optimal rate using 45.5% fewer reasoning steps than complete-trace baselines. Auto Mode delivered 96.6% optimal performance with 59.9% fewer steps than Searchformer, and generated significantly more diverse valid solutions (18.23 vs 1.86 unique paths per task).</p>
    
    <p>Mathematical reasoning experiments fine-tuned Llama-3-8B and Mistral-7B models on the Aug-MATH dataset, showing consistent improvements across both architectures. Mistral-7B with trace dropping achieved 18.6% accuracy versus 16.9% for the baseline (10% relative improvement), while maintaining shorter reasoning traces. Performance degraded gracefully as dropping probability increased, indicating robust controllability.</p>

    <p>Rigorous ablation studies compared Dualformer against naive mixing approaches and individual dropping strategy components, consistently demonstrating the superiority of the hierarchical dropping structure. Evaluation used comprehensive metrics including success rates across multiple samples, solution optimality measures, diversity counts, and computational efficiency indicators, providing strong evidence for both the method's effectiveness and its practical advantages in balancing reasoning quality with computational cost.</p>

    <div class="non-interactive-image">
        <img src="maze.jpg" alt="maze" title="experiments" style="width: 600px; height: auto;">
        <p><em>Inference Modes of Dualformer</em></p>
    </div>

    <h3>5. Final Thoughts</h3>

    <p>Dualformer represents a promising advancement in making AI reasoning systems more adaptable and efficient. The approach demonstrates significant potential across multiple dimensions: it could scale to larger models while reducing computational costs, enable deployment in resource-constrained environments, and facilitate better human-AI collaboration through controllable reasoning depth. The hierarchical structure also opens possibilities for curriculum learning approaches that gradually build reasoning complexity during training.</p>
    <p>However, several limitations constrain its immediate widespread adoption. The method's dependence on well-structured reasoning traces and domain-specific dropping strategies limits its applicability to arbitrary reasoning tasks. Testing has been confined to relatively small models and specific domains (maze navigation, puzzle-solving, and mathematical reasoning), leaving questions about scalability to larger language models and diverse reasoning challenges unanswered. The need for careful tuning of dropping probabilities suggests the approach may not achieve full domain-agnostic generalization.</p>
    <p>Despite these constraints, Dualformer marks a significant step toward more flexible reasoning systems that can dynamically balance computational depth with task requirements. This adaptive capability could fundamentally transform how we deploy AI systems that must navigate the perpetual trade-off between speed and accuracy, particularly in real-world applications where both efficiency and reasoning quality are critical.</p>

    <h4><em>Research Partners</em></h4>
    <ul>
        <li><em>Claude Sonnet 4</em></li>
        <li><em>illuminate.google.com</em></li>
    </ul>
    <p>For more information, read the paper <a href="https://arxiv.org/pdf/2410.09918v1" target="_blank">here</a>.</p>
    <p><b>Thanks for reading!</b></p>
</body>
</html>