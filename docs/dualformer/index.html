<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning to Think - Decoding Dualformer</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0; /* original 20px */
            color: #333;
        }
        .container {
            width: 90%;
            margin: 20px auto 0 auto;
            position: relative;
        }
        h1, h2 {
            color: #0056b3;
        }
        .interactive-image {
            text-align: center;
            margin: 20px 0;
        }
        .interactive-image img {
            width: 450px; 
            height: auto; 
            cursor: pointer;
            transition: transform 0.3s ease;
            display: block; 
            margin: 0 auto; 
        }
        .interactive-image img:hover {
            transform: scale(2.5);
        }
        .non-interactive-image {
            text-align: center;
            margin: 20px 0;
        }
        .non-interactive-image img {
            width: 450px; /* Fixed width */
            height: auto; /* Maintain aspect ratio */
            display: block; /* Ensures the image is centered */
            margin: 0 auto; /* Centers the image horizontally */
        }
        .highlight {
            background-color: #f0f8ff;
            padding: 5px;
            border-radius: 5px;
        }
        .sidebar {
            position: fixed;
            top: 0;
            left: 0;
            width: 300px;
            height: 100%;
            background: #f5f8fa;
            border-right: 1px solid #ddd;
            padding: 30px 15px 15px 15px;
            box-sizing: border-box;
            z-index: 1000;
        }
        .sidebar h2 {
            font-size: 1.2em;
            margin-bottom: 20px;
            color: #0056b3;
        }
        .sidebar ul {
            list-style: none;
            padding: 0;
        }
        .sidebar ul li {
            margin-bottom: 15px;
        }
        .sidebar ul li a {
            color: #333;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.2s;
        }
        .sidebar ul li a:hover {
            color: #0056b3;
        }
        .main-content {
            margin-left: 320px;
            padding: 0 20px;
        }
        .sidebar-linkedin {
            position: absolute;
            left: 5%;
            bottom: 30px;
            /* transform: translateX(-5%); */
            text-align: left;
        }
        .sidebar-linkedin img.profile-pic {
            width: 56px;
            height: 56px;
            border-radius: 50%;
            border: 2px solid #0056b3;
            object-fit: cover;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
            transition: box-shadow 0.2s;
        }
        .sidebar-linkedin img.profile-pic:hover {
            box-shadow: 0 4px 16px rgba(0,86,179,0.18);
        }
        .sidebar-linkedin a {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        .sidebar-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            background: rgba(0,0,0,0.3);
            z-index: 1500;
        }
        .sidebar.open ~ .sidebar-overlay {
            display: block;
        }
        /* Responsive sidebar styles */
        @media (max-width: 900px) {
        .sidebar {
            position: fixed;
            left: -320px;
            top: 0;
            width: 300px;
            height: 100%;
            transition: left 0.3s;
            z-index: 2000;
        }
        .sidebar.open {
            left: 0;
        }
        /*.main-content { 
            margin-left: 0;
            padding: 0 10px;
        }*/
         .main-content {
            margin-left: 0; /* <-- Fix: remove left margin on mobile */
            margin-top: 80px; /* Adjust as needed for your button height */
            padding: 0 10px;
        }
        .sidebar-toggle {
            display: block;
            position: fixed;
            top: 20px;
            left: 20px;
            z-index: 2500;  /* Lower than sidebar's 2000 */
            background: #0056b3;
            color: #fff;
            border: none;
            border-radius: 4px;
            padding: 10px 14px;
            font-size: 18px;
            cursor: pointer;
        }
        }
        @media (min-width: 901px) {
        .sidebar-toggle {
            display: none;
        }
        }
    </style>
</head>
<body>
    <button class="sidebar-toggle" onclick="toggleSidebar()">☰ Menu</button>
    <div class="container">
        <div class="sidebar" id="sidebar">
            <!-- <h2><a href="/index.html">Home</a></h2> -->
            <h2>
                <a href="/index.html" style="display: flex; align-items: center; gap: 8px;">
                    <img src="/images/home.jpg" alt="Home" style="width: 24px; height: 24px; vertical-align: middle;">
                    Home
                </a>
            </h2>
            <h2>Technical Reviews</h2>
            <ul>
                <li style="font-size: 0.85em;"><a href="/docs/dualformer/index.html">Learning to Think - Decoding Dualformer</a></li>
                <li style="font-size: 0.85em;"><a href="/docs/software3/index.html">Beyond Programming - Changing Technology Landscape</a></li>
            </ul>
            <h2>Developer Toolkits</h2> 
            <ul>
                <li style="font-size: 0.85em;"><a href="/docs/async_api/index.html">Building Robust AI Systems</a></li>
            </ul>
            <h2>Mindset Reset</h2>
            <ul>
                <li style="font-size: 0.85em;"><a href="/docs/arena/index.html">Step into the Arena</a></li>
            </ul>       
            <div class="sidebar-linkedin">
                <a href="https://www.linkedin.com/in/lavanya-basavaraju/" target="_blank" title="Connect on LinkedIn">
                    <img src="/images/LB_photo.jpg" alt="Lavanya Basavaraju" class="profile-pic" />
                    Lavanya Basavaraju
                </a>
            </div>
        </div>
    <div class="sidebar-overlay" id="sidebarOverlay"></div>
    <div class="main-content">
    <h1>Learning to Think - Decoding Dualformer</h1>
    <p><em>(Bridging system 1 and system 2 thinking through transformers)</em></p>
    <p style="font-size: 0.9em; line-height: 1.3;">
        <em><b>Author:</b> <a href="https://www.linkedin.com/in/lavanya-basavaraju/" target="_blank">Lavanya Basavaraju</a>; Published on July 04, 2025 </em><br>
        <em>If you have any questions and/or feedback, feel free to reach out at <a href="mailto:brainsesh@gmail.com">brainsesh@gmail.com</a></em>
    </p>

    <p>In this article, I talk about my understanding, personal impressions, and key takeaways on the <em><a href="https://arxiv.org/pdf/2410.09918v1" target="_blank">“Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces”</a></em> paper released by FAIR at Meta on October 15, 2024.</p>

    <h3>Why is this paper interesting? </h3>
    <p>A lot of focus today in the space of Artificial Intelligence (AI) is about a single model that can think and reason at par with an average human being or better than an average human being. There is substantial curiosity and active research around how the large language models can think, reason, and act with the help of agentic frameworks. We will not get into that here. We will talk about <em><b>thinking</b></em>. The process of thinking, the psychology of thinking, and the reproducibility of thinking. The last one is where this paper comes in.  </p>
    <p>So, let’s start!</p>

    <h3>1. The process and the psychology of thinking    </h2>

    <p>A significant portion of civilization results from human thought. And if we were to understand the process of thinking, dual process theory is one of the key concepts. Explained in 1974 by Wason and Evans and popularized by Kahneman in 2017 (Thinking Fast and Slow), dual process theory proposes that human cognition operates through two distinct systems of thinking.</p>
    <ul>
        <li><strong>System 1:</strong> fast, automatic and intuitive </li>
        <li><strong>System 2:</strong> slow, deliberate and effortful </li>
    </ul>

    <div class="non-interactive-image">
        <img src="system.jpg" alt="systems" title="systems of thinking">
        <p><em>System 1 vs System 2 Thinking</em></p>
    </div>


    <p>
    Essentially, System 1 relies on mental shortcuts easily at our disposal from memory to make quick opinions, judgements and decisions, and System 2 requires cognitive resources for systematic reasoning and analysis, and typically comes into play when called to make more careful evaluation.
    <br> <br>
    And there is a beautiful play of information, speed, and accuracy that becomes essential to look at as we understand this dual process theory for thinking. We always have some information to make a decision, even if it is from memory or some kind of input at the moment. System 1 will use that information to make the decision fast, while System 2 may wait a little longer to collect more information if necessary.
    <br> <br>
    Some decisions, like <em>choosing what to eat for breakfast</em>, might not require us to be so accurate as the risk of making that decision is generally low. In that case System 1 thinking is all that’s needed. But for higher risk decisions like <em>choosing an international graduate degree program or a family buying a first-time home</em>, the risk involved is much higher and the decision would require more thought, information, and analysis. Sometimes this <b>requires multiple trusted individuals using their System 2 thinking</b> to make decisions.
    </p>
   
    <h3>2. Ideas explored in the paper  </h2>

    <p>Dualformer is a novel transformer-based architecture that integrates both fast and slow reasoning modes into a single model, inspired by this dual process theory. The model addresses a fundamental trade-off in AI reasoning systems: fast models are computationally efficient but less accurate, while slow models that generate detailed reasoning traces are more accurate but computationally expensive.</p>

    <p>The core innovation lies in structured trace dropping during training. Instead of training separate models for fast and slow reasoning, Dualformer learns from <em><b>randomized reasoning traces</b></em> (think of this as a step by step process to complete a given task) where different parts are systematically dropped according to four hierarchical levels:<p>
    <ul>
        <li><strong>Level 1:</strong> Drop "close" (successful completion of individual steps) clauses from <em><a href="https://arxiv.org/pdf/2402.14083" target="_blank">A* search</a></em> traces</li>
        <li><strong>Level 2:</strong> Additionally drop cost information from remaining clauses</li>
        <li><strong>Level 3:</strong> Further drop 30% of "create" clauses (creating/executing individual steps) randomly</li>
        <li><strong>Level 4:</strong> Drop the entire reasoning trace, keeping only the final solution</li>
    </ul>

    <p>Imagine training a new detective (say, an intern) by showing them case files with varying levels of detail. Here, "close" clauses indicate closed investigations, while "create" clauses indicate new ones.</p>
    <ul>
        <li><strong>Level 0:</strong> The intern detective has all information available at once for a full methodical investigation </li>
        <li><strong>Level 1:</strong> “Close” clauses are hidden, meaning the detective doesn’t know the investigations that are "closed" or the final outcome, but still has all active leads and knows the costs of pursuing these leads </li>
        <li><strong>Level 2:</strong> Both “close” clauses and cost calculations are removed, meaning the detective doesn’t know the closed investigations, final outcome, or the cost of pursuing those investigations </li>
        <li><strong>Level 3:</strong> Further, a random 30% of “create” clauses are dropped, meaning the detective doesn’t have information about 30% of the investigation cases </li>
        <li><strong>Level 4:</strong> Drop entire reasoning trace, meaning the intern detective is given the final outcome of the case without any notes on the investigations and has to try trace back the details of all/necessary investigations to arrive at the final outcome </li>
    </ul>
    
    <p>Learning in this systematic approach can teach the intern detective to solve cases efficiently when they are working on an active case in the future. </p>

    <div class="non-interactive-image">
        <img src="model.jpg" alt="model" title="model architecture" style="width: 800px; height: auto;">
    </div>
    
    <p>More about A* algorithm can be understood from the <a href="https://arxiv.org/pdf/2402.14083" target="_blank">Searchformer</a> paper released by Meta in April 2024. Very briefly, A* is a pathfinding algorithm that finds the shortest route between two points, like navigating through a maze from start to goal. </p>

    <ul>
    <li> It works by maintaining two lists: a "create" list of locations it might explore next, and a "close" list of locations it has already checked.   </li>
        <ul>
            <li> For each potential location, A* calculates two key values: the actual cost to reach that spot from the start, and a heuristic estimate of how far it still is from the goal (like manhattan distance in a grid). It combines these to prioritize which location to explore next, always choosing the most promising option.   </li>
        </ul>
    <li> From the intern detective perspective, say there are 2 files – “active leads” (create list) of potential clues to investigate next and “case closed” (close list) of leads already thoroughly examined.    </li>
        <ul>   
            <li> For each active lead, the intern detective should calculate both the effort already invested to reach that point and estimate the remaining work needed to solve the case, always pursuing the most promising lead first.   </li>
        </ul> 
    </ul>
    <p>During training, each example randomly selects a dropping strategy from these levels, enabling the model to learn shortcuts in reasoning while maintaining the ability to generate full traces when needed. At inference time, Dualformer can operate in three modes:</p>
    <ul>
        <li><strong>Fast mode:</strong> Outputs solutions directly without reasoning steps</li>
        <li><strong>Slow mode:</strong> Generates complete reasoning traces plus solutions</li>
        <li><strong>Auto mode:</strong> Automatically decides which approach to use</li>
    </ul>

    <div class="non-interactive-image">
        <img src="mode.jpg" alt="modes" title="inference modes" style="width: auto; height: 300px;">
        <p><em>Inference Modes of Dualformer</em></p>
    </div>


    <p>So, Dualformer is suggesting a unified system that can dynamically adjust its reasoning depth based on task requirements and user preferences. This mimics the human thinking process, where we unconsciously switch between intuitive quick decisions (System 1) and deliberate analytical thinking (System 2) depending on the situation's complexity and stakes.</p>
    <p>The approach also addresses practical deployment concerns: a single model that can operate in multiple modes is more efficient than maintaining separate systems, while the structured dropping reduces training time by shortening input sequences.</p>


    <h3>3. Model Architecture </h3>

    <div class="non-interactive-image">
        <img src="architecture.jpg" alt="architecture" title="architecture" style="width: auto; height: 500px;">
        <p><em>Encoder-Decoder Architecture</em></p>
    </div>

    <p>Most of the large generative models today use decoder-only framework. Dualformer uses encoder-decoder architecture, originally as explained in Attention is all you need <a href="https://arxiv.org/pdf/1706.03762" target="_blank">(Vaswani et al., 2017)</a> and T5 architecture <a href="https://arxiv.org/pdf/1910.10683" target="_blank">(Raffel et al., 2020)</a>. A few changes include the rotary position encoding (RoPE) and the format of sequences. The <b>&lt;prompt&gt;</b> goes into the encoder along with the task specification. Decoder processes either a <b>&lt;trace&gt;</b><b>&lt;plan&gt;</b> sequence (slow mode or search-augmented model) or only a <b>&lt;plan&gt;</b> sequence (fast mode or solution-only models).</p>

    <p>The models are instantiated with T5 and RoPE for position encoding, and trained with 100K training samples. Model sizes are 15M and 46M for Maze and Sokoban tasks respectively. </p>

    <p>For the fast mode, Dualformer is trained on sequence data that only includes the optimal final solution without a reasoning trace. The slow mode baseline is the Complete-Trace model trained on data with complete A* search traces.</p>

    <h3>4. Experiments and Evidence </h3>

    <p>I really liked the experimental design. The authors are basically trying to answer the below key questions which align not only the thinking process, but also how one would want to use a large language model today for reasoning:</p>
    <ul>
        <li>Does Dualformer outperform corresponding baselines in fast, slow and auto mode? Does it generate more diverse plans? </li>
        <li>In slow model, does Dualformer lead to faster reasoning, i.e., output a shorter trace?</li>
        <li>Does the structured trace dropping technique generalize to LLMs trained on natural language datasets?</li>
    </ul>

    <p>In terms of the evaluation process, whether a model generates correct or optimal plans is measured using two metrics: <b>1-Solved-64</b> and <b>1-Optimal-64</b>. </p>
    <ul>
        <li>64 responses are randomly sampled from a trained model </li>
        <li>Each response is parsed and evaluated regardless of the generated trace part</li>
        <ul>
            <li>1-Solved-64: If any of the 64 plans is correct, i.e. plan is feasible and reaches the goal/finish, this task is labelled as success for the 1-Solved-64 metric</li>
            <li>1-Optimal-64:If any of the 64 plans is optimal, this task is labelled as success for the 1-Optimal-64 metric </li>
        </ul>
        <li>This is repeated for 1000 unseen evaluation tasks and report the average success rate</li>
        <li>To investigate the robustness of each method, metrics 3-Solved-64 and 3-Optimal-64, where a task is labelled as success if at least 3 plans are correct or optimal are also reported</li>
    </ul>
    <p>The authors conducted experiments across pathfinding tasks and mathematical reasoning to validate Dualformer's effectiveness. </p>

    <p>For pathfinding, they used maze navigation (15×15 to 30×30) and Sokoban puzzles with 100k training examples from A* search traces. Results demonstrated substantial improvements: </p>
    <ul>    
    <li>Fast Mode achieved 80% optimal solutions on 30×30 mazes versus 30% for solution-only baselines (2.67× improvement), </li>
    <li>Slow Mode reached 97.6% optimal rate using 45.5% fewer reasoning steps than complete-trace baselines, and</li>
    <li>Auto Mode delivered 96.6% optimal performance with 59.9% fewer steps than Searchformer and generated significantly more diverse valid solutions (18.23 vs 1.86 unique paths per task).</li>
    </ul>

    <p>
    To answer the third question, “does the structured trace dropping technique generalize to LLMs trained on natural language datasets?”, the authors conducted mathematical reasoning experiments by fine-tuning Llama-3.1-8B and Mistral-7B models on the Aug-MATH dataset. 
    <br> <br>
    This Aug-MATH dataset creation is a nice experiment in itself. The dataset is derived from the MATH dataset (Hendrycks et al., 2021) that contains 7500 train and 5000 test examples of math questions and solutions. They take this data and use Llama-3.1-70B-Instruct model to rewrite the solutions with detailed intermediate steps. And then to introduce diversity, they sample 4 responses for each question. This produces an overall dataset of 30K training examples and 5K testing examples. 
    <br>  <br>   
    The evaluation shows consistent improvements from LLM finetuning, which proves that using this framework can be generalized. The key idea is that if one were to finetune this framework for a specific reasoning task, one can achieve much better performance compared to baseline.
    </p>
    
    <!-- <div class="non-interactive-image">
        <img src="maze.jpg" alt="maze" title="experiments" style="width: 600px; height: auto;">
        <p><em>Inference Modes of Dualformer</em></p>
    </div> -->

    <h3>5. Final Thoughts</h3>
    
    <p>Overall, Dualformer presents a compelling framework that bridges the gap between fast intuitive responses and deliberate reasoning by training models that can adapt to different thinking modes. </p>
    
    <p>What makes this work particularly thought-provoking is its technical reproducibility of human-like cognitive processes, the ability to seamlessly switch between System 1 and System 2 thinking patterns, while simultaneously reducing computational overhead through intelligent sequence shortening and learning from randomized reasoning traces.</p>
    
    <p>The authors' choice to explore encoder-decoder architectures alongside the dominant decoder-only paradigm demonstrates refreshing architectural diversity and suggests potential avenues for sophisticated reasoning capabilities that extend beyond current approaches. It will be fascinating to see if this line of research and experimentation can make small reasoning models perform better and more generalizable. </p>
    
    <p>In short, my key takeaways from the paper are:</p>
    <ul>
        <li>Potential method for replicating dual-process thinking technically</li>
        <li>Training a model capable of learning both fast and slow modes of thinking by utilizing randomized reasoning traces </li>
        <li>While encoding-only architectures excel and large decoder-only models continue to impress, the encoder-decoder approach explored in Dualformer emerges as potentially crucial for sophisticated thinking and reasoning capabilities </li>
    </ul>
    <p>Kudos to all the authors and stakeholders who took this idea and produced quality studies with meaningful results. Not all ideas are pursued, those that do aren’t always successful. It is a hard process!</p>
    <br>

    <p><b>Thanks for reading!</b></p>
    <!-- <br> -->
    <p style="font-size: 0.9em; line-height: 1.2;">
        <em>For more information, read the paper <a href="https://arxiv.org/pdf/2410.09918v1" target="_blank">here</a>. For more articles like this, visit <a href="https://brainsesh.github.io/" target="_blank">blog</a>.</em><br>
        <em>If you have any questions and/or feedback, feel free to reach out at <a href="mailto:brainsesh@gmail.com">brainsesh@gmail.com</a></em><br>
        <em>The views in this article are those of the contributor alone and do not represent their employers or affiliated organizations. This information is for informational purposes only and should not be taken as professional advice or an official statement. Readers should use their own judgment when evaluating the opinions presented. </em>
        <!-- <em>This article is licensed under <a href="https://creativecommons.org/licenses/by/4.0/legalcode" target="_blank">CC BY 4.0</a></em> <br> -->
        <!-- <em>Research Partners: Ryan Borowicz, Claude Sonnet 4, illuminate.google.com</em><br> -->
    </p>

    </div>
    </div>
    <script>
        /*function toggleSidebar() {
            var sidebar = document.getElementById('sidebar');
            var overlay = document.getElementById('sidebarOverlay');
            sidebar.classList.toggle('open');
            overlay.style.display = sidebar.classList.contains('open') ? 'block' : 'none';
        }
        document.getElementById('sidebarOverlay').onclick = function() {
            document.getElementById('sidebar').classList.remove('open');
            this.style.display = 'none';
        }; */
        function toggleSidebar() {
            var sidebar = document.getElementById('sidebar');
            var overlay = document.getElementById('sidebarOverlay');
            var toggleBtn = document.querySelector('.sidebar-toggle');
            sidebar.classList.toggle('open');
            overlay.style.display = sidebar.classList.contains('open') ? 'block' : 'none';
            // Hide the button when sidebar is open (on mobile)
            if (window.innerWidth <= 900) {
                toggleBtn.style.display = sidebar.classList.contains('open') ? 'none' : 'block';
            }
        }
        document.getElementById('sidebarOverlay').onclick = function() {
            document.getElementById('sidebar').classList.remove('open');
            this.style.display = 'none';
            // Show the toggle button again
            if (window.innerWidth <= 900) {
                document.querySelector('.sidebar-toggle').style.display = 'block';
            }
        };
        // Optional: Hide sidebar if window resized to desktop
        window.addEventListener('resize', function() {
            var sidebar = document.getElementById('sidebar');
            var overlay = document.getElementById('sidebarOverlay');
            var toggleBtn = document.querySelector('.sidebar-toggle');
            if (window.innerWidth > 900) {
                sidebar.classList.remove('open');
                overlay.style.display = 'none';
                toggleBtn.style.display = 'none';
            } else {
                toggleBtn.style.display = sidebar.classList.contains('open') ? 'none' : 'block';
            }
        });
        /*window.addEventListener('resize', function() {
            var toggleBtn = document.querySelector('.sidebar-toggle');
            if (window.innerWidth > 900) {
                toggleBtn.style.display = 'none';
            } else {
                toggleBtn.style.display = document.getElementById('sidebar').classList.contains('open') ? 'none' : 'block';
            }
        });*/
    </script>
</body>
</html>